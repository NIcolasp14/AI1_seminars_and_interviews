{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI Seminar - Part 2 - Practical Test (July 2023)\n",
        "\n",
        "**Συμπληρώστε παρακάτω τα στοιχεία σας:**\n",
        "\n",
        "**Επώνυμο:         **\n",
        "\n",
        "**Όνομα:           **\n",
        "\n",
        "**Σχολή:           **\n",
        "\n",
        "**Α.Μ.:            **\n",
        "\n",
        "\n",
        "\n",
        "### Ζητούμενα - Οδηγίες\n",
        "Καλείστε να υλοποιήσετε δύο διαφορετικές αρχιτεκτονικές νευρωνικών δικτύων για να επιλύσετε το πρόβλημα της ταξινόμησης εικόνων σε κλάσεις. Το dataset στο οποίο θα εργαστείτε είναι το **CIFAR-10**. Μπορείτε να βρείτε πληροφορίες και να κατεβάσετε το CIFAR-10 [εδώ](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
        "\n",
        "Θα πρέπει να υλοποιήσετε δύο αρχιτεκτονικές για την **ταξινόμηση των εικόνων σε 10 κλάσεις**:\n",
        "\n",
        "(1) Ένα **συνελικτικό νευρωνικό δίκτυο (Convolutional Neural Network - CNN)**.\n",
        "\n",
        "(2) Ένα **πολυστρωματικό perceptron (MLP) 5 επιπέδων (4 κρυμμένα επίπεδα και 1 επίπεδο εξόδου)**.\n",
        "\n",
        "\n",
        "Χωρίστε τα training & test sets με αναλογία της επιλογής σας, αιτιολογώντας την με συντομία.\n",
        "\n",
        "Για κάθε αρχιτεκτονική, θα πρέπει να εμφανίσετε σε πίνακες τα εξής αποτελέσματα:\n",
        "- accuracy και recall (α) ανά κλάση και (β) συνολικά.\n",
        "- confusion matrix.\n",
        "\n",
        "Στο τέλος, σε ένα κελί κειμένου σχολιάστε σύντομα τα αποτελέσματα και συγκρίνετε τις δύο αρχιτεκτονικές για το συγκεκριμένο πρόβλημα.\n",
        "\n",
        "Μπορείτε να χρησιμοποιήσετε όποιες βιβλιοθήκες, modules, κ.λπ. επιθυμείτε.\n",
        "\n",
        "Για οποιοδήποτε βήμα δεν δίνεται συγκεκριμένη οδηγία (επιλογή παραμέτρων και υπερ-παραμέτρων, πλήθος νευρώνων σε κάθε επίπεδο, είδη στρωμάτων στο CNN, προεπεξεργασία δεδομένων, κ.λπ.) έχετε την ελευθερία επιλογής, παραθέτοντας μια σύντομη εξήγηση της επιλογής σας.\n",
        "\n",
        "**Σε περιπτώσεις όπου εντοπίζεται αντιγραφή, η προσπάθεια θα μηδενίζεται.**\n",
        "\n",
        "Θα πρέπει να ανεβάσετε το notebook σας στο helios στο σημείο που θα σας υποδειχθεί.\n",
        "\n",
        "**Πριν το ανεβάσετε, βεβαιωθείτε ότι έχετε τρέξει όλα τα κελιά κώδικα που υπάρχουν στο notebook σας.**\n",
        "\n",
        "Καλή επιτυχία!\n"
      ],
      "metadata": {
        "id": "hlQtDEpeQf5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "Q9YvBZ-iy01N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset has already been split into the train and test parts"
      ],
      "metadata": {
        "id": "ebl0HBRTC3CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Preparation\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdaThkRby2f-",
        "outputId": "81a403e3-c1ec-47de-8ef0-ccdc83a2f754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "z9bS3f13y4X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional Neural Network (CNN)\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=x_train.shape[1:]))\n",
        "cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(512, activation='relu'))\n",
        "cnn_model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "cnn_model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4FPe6nby6VG",
        "outputId": "734de8af-1196-464b-cea9-2d63acb2bd3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 289s 368ms/step - loss: 1.3818 - accuracy: 0.5012 - val_loss: 1.1143 - val_accuracy: 0.6129\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 282s 360ms/step - loss: 0.9355 - accuracy: 0.6707 - val_loss: 0.8693 - val_accuracy: 0.6971\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 314s 401ms/step - loss: 0.7249 - accuracy: 0.7455 - val_loss: 0.7960 - val_accuracy: 0.7236\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 278s 356ms/step - loss: 0.5790 - accuracy: 0.7993 - val_loss: 0.7839 - val_accuracy: 0.7286\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 284s 363ms/step - loss: 0.4400 - accuracy: 0.8461 - val_loss: 0.7624 - val_accuracy: 0.7563\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 284s 363ms/step - loss: 0.3206 - accuracy: 0.8872 - val_loss: 0.8616 - val_accuracy: 0.7487\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 288s 369ms/step - loss: 0.2218 - accuracy: 0.9237 - val_loss: 0.9809 - val_accuracy: 0.7398\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 277s 354ms/step - loss: 0.1516 - accuracy: 0.9475 - val_loss: 1.0495 - val_accuracy: 0.7462\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 286s 366ms/step - loss: 0.1162 - accuracy: 0.9603 - val_loss: 1.2588 - val_accuracy: 0.7342\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 276s 353ms/step - loss: 0.0978 - accuracy: 0.9656 - val_loss: 1.3881 - val_accuracy: 0.7364\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6075772fe0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multilayer Perceptron (MLP)\n",
        "mlp_model = Sequential()\n",
        "mlp_model.add(Flatten(input_shape=x_train.shape[1:]))\n",
        "mlp_model.add(Dense(256, activation='relu'))\n",
        "mlp_model.add(Dense(128, activation='relu'))\n",
        "mlp_model.add(Dense(64, activation='relu'))\n",
        "mlp_model.add(Dense(32, activation='relu'))\n",
        "mlp_model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "mlp_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "mlp_model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjwVJTYRzBI9",
        "outputId": "b6a335d1-014a-42d2-ff3e-fe868fd12809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 17s 20ms/step - loss: 1.9014 - accuracy: 0.3061 - val_loss: 1.7442 - val_accuracy: 0.3686\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.7160 - accuracy: 0.3811 - val_loss: 1.6520 - val_accuracy: 0.4081\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.6387 - accuracy: 0.4090 - val_loss: 1.6165 - val_accuracy: 0.4256\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.5783 - accuracy: 0.4338 - val_loss: 1.5331 - val_accuracy: 0.4535\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.5261 - accuracy: 0.4523 - val_loss: 1.5355 - val_accuracy: 0.4457\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 1.5035 - accuracy: 0.4606 - val_loss: 1.5380 - val_accuracy: 0.4471\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.4767 - accuracy: 0.4717 - val_loss: 1.5446 - val_accuracy: 0.4504\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.4508 - accuracy: 0.4796 - val_loss: 1.4790 - val_accuracy: 0.4724\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 1.4291 - accuracy: 0.4880 - val_loss: 1.5046 - val_accuracy: 0.4676\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 1.4047 - accuracy: 0.4971 - val_loss: 1.4582 - val_accuracy: 0.4735\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.3830 - accuracy: 0.5064 - val_loss: 1.4362 - val_accuracy: 0.4878\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.3627 - accuracy: 0.5128 - val_loss: 1.4370 - val_accuracy: 0.4883\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 1.3491 - accuracy: 0.5168 - val_loss: 1.4569 - val_accuracy: 0.4773\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.3390 - accuracy: 0.5209 - val_loss: 1.4136 - val_accuracy: 0.5043\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.3191 - accuracy: 0.5285 - val_loss: 1.4303 - val_accuracy: 0.4909\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.3122 - accuracy: 0.5322 - val_loss: 1.4102 - val_accuracy: 0.4962\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.2978 - accuracy: 0.5359 - val_loss: 1.4170 - val_accuracy: 0.4947\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 1.2824 - accuracy: 0.5405 - val_loss: 1.3911 - val_accuracy: 0.5104\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 1.2681 - accuracy: 0.5443 - val_loss: 1.4160 - val_accuracy: 0.4950\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 1.2574 - accuracy: 0.5500 - val_loss: 1.4338 - val_accuracy: 0.4910\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.2530 - accuracy: 0.5514 - val_loss: 1.4183 - val_accuracy: 0.4997\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.2346 - accuracy: 0.5558 - val_loss: 1.4277 - val_accuracy: 0.4936\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.2315 - accuracy: 0.5579 - val_loss: 1.4174 - val_accuracy: 0.5050\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.2223 - accuracy: 0.5603 - val_loss: 1.4327 - val_accuracy: 0.4988\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.2092 - accuracy: 0.5660 - val_loss: 1.4088 - val_accuracy: 0.5071\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.1975 - accuracy: 0.5696 - val_loss: 1.4635 - val_accuracy: 0.4935\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.1881 - accuracy: 0.5739 - val_loss: 1.4249 - val_accuracy: 0.5047\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.1818 - accuracy: 0.5757 - val_loss: 1.4616 - val_accuracy: 0.4888\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 1.1753 - accuracy: 0.5792 - val_loss: 1.4352 - val_accuracy: 0.4964\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.1655 - accuracy: 0.5809 - val_loss: 1.4263 - val_accuracy: 0.5072\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.1590 - accuracy: 0.5833 - val_loss: 1.4174 - val_accuracy: 0.5090\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.1523 - accuracy: 0.5865 - val_loss: 1.4185 - val_accuracy: 0.5109\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.1370 - accuracy: 0.5915 - val_loss: 1.4583 - val_accuracy: 0.5005\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 1.1404 - accuracy: 0.5897 - val_loss: 1.4492 - val_accuracy: 0.5026\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.1248 - accuracy: 0.5970 - val_loss: 1.4772 - val_accuracy: 0.4977\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.1187 - accuracy: 0.5980 - val_loss: 1.4569 - val_accuracy: 0.5031\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.1092 - accuracy: 0.5995 - val_loss: 1.4498 - val_accuracy: 0.5128\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.1054 - accuracy: 0.6053 - val_loss: 1.4552 - val_accuracy: 0.5092\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.0966 - accuracy: 0.6068 - val_loss: 1.4316 - val_accuracy: 0.5152\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.0914 - accuracy: 0.6080 - val_loss: 1.4531 - val_accuracy: 0.5157\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.0820 - accuracy: 0.6108 - val_loss: 1.4511 - val_accuracy: 0.5104\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.0759 - accuracy: 0.6140 - val_loss: 1.4604 - val_accuracy: 0.5050\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.0725 - accuracy: 0.6160 - val_loss: 1.4731 - val_accuracy: 0.5062\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 1.0641 - accuracy: 0.6155 - val_loss: 1.4619 - val_accuracy: 0.5090\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.0593 - accuracy: 0.6191 - val_loss: 1.5055 - val_accuracy: 0.5056\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.0541 - accuracy: 0.6201 - val_loss: 1.4913 - val_accuracy: 0.5049\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.0484 - accuracy: 0.6236 - val_loss: 1.5299 - val_accuracy: 0.4940\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.0439 - accuracy: 0.6255 - val_loss: 1.5135 - val_accuracy: 0.4981\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.0345 - accuracy: 0.6266 - val_loss: 1.5127 - val_accuracy: 0.5081\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.0326 - accuracy: 0.6300 - val_loss: 1.5094 - val_accuracy: 0.5063\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6071b22740>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Results Comparison\n",
        "cnn_predictions = np.argmax(cnn_model.predict(x_test), axis=1)\n",
        "mlp_predictions = np.argmax(mlp_model.predict(x_test), axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1Hs5H7jzFFU",
        "outputId": "a9af97ca-7c02-4d7a-b559-464f8e32a8a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 15s 47ms/step\n",
            "313/313 [==============================] - 1s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy and recall per class\n",
        "cnn_accuracy_per_class = np.mean(cnn_predictions == np.argmax(y_test, axis=1))\n",
        "mlp_accuracy_per_class = np.mean(mlp_predictions == np.argmax(y_test, axis=1))\n",
        "\n",
        "cnn_recall_per_class = classification_report(np.argmax(y_test, axis=1), cnn_predictions)\n",
        "mlp_recall_per_class = classification_report(np.argmax(y_test, axis=1), mlp_predictions)"
      ],
      "metadata": {
        "id": "iGOD4xaEzHZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate overall accuracy\n",
        "cnn_accuracy_overall = np.mean(cnn_accuracy_per_class)\n",
        "mlp_accuracy_overall = np.mean(mlp_accuracy_per_class)"
      ],
      "metadata": {
        "id": "9QBe-mCHzKLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate confusion matrix\n",
        "cnn_confusion_matrix = confusion_matrix(np.argmax(y_test, axis=1), cnn_predictions)\n",
        "mlp_confusion_matrix = confusion_matrix(np.argmax(y_test, axis=1), mlp_predictions)"
      ],
      "metadata": {
        "id": "t5IqRKIxzLZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results\n",
        "print(\"CNN Accuracy per class:\", cnn_accuracy_per_class)\n",
        "print(\"CNN Recall per class:\\n\", cnn_recall_per_class)\n",
        "print(\"CNN Overall Accuracy:\", cnn_accuracy_overall)\n",
        "print(\"CNN Confusion Matrix:\\n\", cnn_confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_twmSC5UzNOP",
        "outputId": "379d8445-e296-4328-b717-e90ccc29e9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Accuracy per class: 0.7364\n",
            "CNN Recall per class:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.78      0.76      1000\n",
            "           1       0.87      0.84      0.86      1000\n",
            "           2       0.65      0.66      0.65      1000\n",
            "           3       0.50      0.64      0.56      1000\n",
            "           4       0.73      0.65      0.69      1000\n",
            "           5       0.65      0.59      0.62      1000\n",
            "           6       0.88      0.71      0.79      1000\n",
            "           7       0.82      0.74      0.78      1000\n",
            "           8       0.84      0.86      0.85      1000\n",
            "           9       0.78      0.87      0.82      1000\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.74      0.74     10000\n",
            "weighted avg       0.75      0.74      0.74     10000\n",
            "\n",
            "CNN Overall Accuracy: 0.7364\n",
            "CNN Confusion Matrix:\n",
            " [[782  17  52  16  10   5   7  10  60  41]\n",
            " [ 14 842   2   9   1   4   1   3  24 100]\n",
            " [ 70   6 661  79  65  45  26  24  13  11]\n",
            " [ 39  10  62 643  31 122  33  21  13  26]\n",
            " [ 32   5  69 105 649  58  12  47  15   8]\n",
            " [ 23   3  55 218  34 595  10  44   6  12]\n",
            " [  9   8  72 117  36  23 714   7   9   5]\n",
            " [ 23   3  30  64  53  59   4 743   3  18]\n",
            " [ 44  29  13  15   3   2   2   1 862  29]\n",
            " [ 19  46   7  14   3   4   1  10  23 873]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results\n",
        "print(\"MLP Accuracy per class:\", mlp_accuracy_per_class)\n",
        "print(\"MLP Recall per class:\\n\", mlp_recall_per_class)\n",
        "print(\"MLP Overall Accuracy:\", mlp_accuracy_overall)\n",
        "print(\"MLP Confusion Matrix:\\n\", mlp_confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_K_3-42ysiu",
        "outputId": "d3b880c1-d946-4969-d8cc-e7ffe3e52d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Accuracy per class: 0.5063\n",
            "MLP Recall per class:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.63      0.58      1000\n",
            "           1       0.63      0.61      0.62      1000\n",
            "           2       0.39      0.32      0.35      1000\n",
            "           3       0.35      0.31      0.33      1000\n",
            "           4       0.43      0.46      0.45      1000\n",
            "           5       0.41      0.41      0.41      1000\n",
            "           6       0.52      0.58      0.55      1000\n",
            "           7       0.60      0.53      0.56      1000\n",
            "           8       0.55      0.69      0.61      1000\n",
            "           9       0.60      0.54      0.57      1000\n",
            "\n",
            "    accuracy                           0.51     10000\n",
            "   macro avg       0.50      0.51      0.50     10000\n",
            "weighted avg       0.50      0.51      0.50     10000\n",
            "\n",
            "MLP Overall Accuracy: 0.5063\n",
            "MLP Confusion Matrix:\n",
            " [[633  36  39  19  30  22  16  24 140  41]\n",
            " [ 57 609  18  19   9  21  16  22  91 138]\n",
            " [ 96  16 317  96 153  85 111  66  45  15]\n",
            " [ 36  18  90 311  79 199 117  46  62  42]\n",
            " [ 67   8 123  59 456  57 120  58  39  13]\n",
            " [ 26  11  79 189  68 407  94  61  49  16]\n",
            " [ 15  13  76  84 106  65 582  21  20  18]\n",
            " [ 56  26  45  58 107  85  29 526  33  35]\n",
            " [124  62   2  15  25  19  10  16 687  40]\n",
            " [ 56 174  16  29  16  26  25  34  89 535]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course the CNN outperforms the MLP. The CNN does a decent job in distinguishing the 10 classes, while the MLP completely fails. It must be pointed out though, that the CNN had more neurons. While observing the training one can safely assume that the CNN actually learns the task, while the MLP just slightly improves in each epoch and possibly overfits. CNN's results in the test set can be greatly ameliorated by tweaking the number of neurons/layers and generally by performing hyperparameter tuning. The same case can't be made for MLP. These results were expected."
      ],
      "metadata": {
        "id": "pG1pnIYmC5S0"
      }
    }
  ]
}